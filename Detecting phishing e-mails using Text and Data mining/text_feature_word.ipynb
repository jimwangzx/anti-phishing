{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#!pip install --upgrade coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "23"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 36
    }
   ],
   "source": [
    "import coremltools\n",
    "from coremltools.converters import sklearn\n",
    "\n",
    "dict = {'account':42.11758, 'member':19.31017, 'access':17.05149, 'email':16.6749, 'address':15.3276,\n",
    "             'update':15.3276, 'price':12.55556, 'market':10.23963, 'online':9.770984, 'information':9.474589,\n",
    "             'work':8.331161, 'credit':5.883471, 'response':4.504742, 'offer':3.3573, 'transaction':2.809165,\n",
    "             'agreement':1.863823, 'registration':1.791679, 'person':1.522086, 'system':1.276965,\n",
    "             'process':1.076627, 'service':0.895862, 'request':0.616316, 'message':0.32805}\n",
    "\n",
    "key_words = ['account', 'member', 'access', 'email', 'address',\n",
    "             'update', 'price', 'market', 'online', 'information',\n",
    "             'work', 'credit', 'response', 'offer', 'transaction',\n",
    "             'agreement', 'registration', 'person', 'system',\n",
    "             'process', 'service', 'request', 'message']\n",
    "\n",
    "# key_words = ['account', 'member', 'access', 'email', 'address',\n",
    "#              'update', 'price', 'market', 'online', 'information',\n",
    "#              'work', 'credit', 'response', 'offer', 'transaction',\n",
    "#              'agreement', 'offer', 'registration']\n",
    "\n",
    "len(key_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MailContentsFeaturize(object):\n",
    "    def __init__(self, content):\n",
    "        self.content = content.lower()\n",
    "        \n",
    "    # 提取特征方法\n",
    "    def contain_key(self, key):\n",
    "        if key in self.content:\n",
    "            # return int(1)\n",
    "            return float(dict[key])\n",
    "        else:\n",
    "            return float(0)\n",
    "    \n",
    "    def run(self):\n",
    "        data = {}\n",
    "        for word in key_words :\n",
    "            data[word] = self.contain_key(word)\n",
    "        return data\n",
    "    \n",
    "    def get_train_data(self):\n",
    "        data = []\n",
    "        for word in key_words :\n",
    "            data.append(self.contain_key(word))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_head_train_path_0 = '../data/phishing/IWSPA-AP-traindata/phish/'\n",
    "no_head_train_path_1 = '../data/phishing/IWSPA-AP-traindata/legit/'\n",
    "no_head_test_path = '../data/phishing/IWSPA-APTestData/testdata_noheaders/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.encode('utf-8').decode('utf-8')\n",
    "    while '\\n' in text:\n",
    "        text = text.replace('\\n', ' ')\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    words = text.split()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    stripped = []\n",
    "    for token in words: \n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            stripped.append(new_token.lower())\n",
    "    text = ' '.join(stripped)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_data(path):\n",
    "    text_list = list()\n",
    "    files = os.listdir(path)\n",
    "    for text_file in files:\n",
    "        file_path = os.path.join(path, text_file)\n",
    "        read_file = open(file_path,'r+')\n",
    "        read_text = read_file.read()\n",
    "        read_file.close()\n",
    "        cleaned_text = clean_text(read_text)\n",
    "        # append text\n",
    "        # text_list.append(cleaned_text)\n",
    "        \n",
    "        featurized = MailContentsFeaturize(cleaned_text)\n",
    "        # append features\n",
    "        # text_list.append(featurized.run())\n",
    "        text_list.append(featurized.get_train_data())\n",
    "    return text_list, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "no_head_train_0, temp = get_data(no_head_train_path_0)\n",
    "no_head_train_1, temp = get_data(no_head_train_path_1)\n",
    "# no_head_test, no_head_files = get_data(no_head_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_head_train = no_head_train_0 + no_head_train_1\n",
    "no_head_labels_train = ([int(0)] * len(no_head_train_0)) + ([int(1)] * len(no_head_train_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# tf_vectorizer = CountVectorizer()\n",
    "# X = tf_vectorizer.fit_transform(no_head_train)\n",
    "# print ('#total words', np.matrix.sum(X.todense()))\n",
    "# print ('#unique words',len(set(tf_vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(len(no_head_labels_train))\n",
    "train_data = np.array(no_head_train)[shuffled_indices]\n",
    "train_data = train_data.tolist()\n",
    "train_label = np.array(no_head_labels_train)[shuffled_indices]\n",
    "train_label = train_label.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp_train_data = train_data[0:int(0.8*len(train_data))]\n",
    "temp_train_label = train_label[0:int(0.8*len(train_label))]\n",
    "temp_test_data = train_data[int(0.8*len(train_data)):]\n",
    "temp_test_labels = train_label[int(0.8*len(train_label)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9205240174672489"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 48
    }
   ],
   "source": [
    "#Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(temp_train_data,temp_train_label)\n",
    "\n",
    "coreml_model = sklearn.convert(dt_model, key_words, 'output')\n",
    "coreml_model.save('coreml_dt.mlmodel')\n",
    "\n",
    "dt_predictions = dt_model.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'output': 1, 'classProbability': {0: 0.0, 1: 1.0}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 49
    }
   ],
   "source": [
    "model = coremltools.models.MLModel('coreml_dt.mlmodel')\n",
    "# model.predict({'input': temp_test_data})\n",
    "pred_out_put = model.predict({'account':42.11758, 'member':19.31017, 'access':17.05149, 'email':16.6749, 'address':15.3276,\n",
    "             'update':15.3276, 'price':12.55556, 'market':10.23963, 'online':9.770984, 'information':9.474589,\n",
    "             'work':8.331161, 'credit':5.883471, 'response':4.504742, 'offer':3.3573, 'transaction':2.809165,\n",
    "             'agreement':1.863823, 'registration':1.791679, 'person':1.522086, 'system':1.276965,\n",
    "             'process':1.076627, 'service':0.895862, 'request':0.616316, 'message':0.32805})\n",
    "print(pred_out_put[\"output\"])\n",
    "pred_out_put\n",
    "# accuracy_score(temp_test_labels,dt_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[ 60  63]\n",
      " [ 28 994]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.49      0.57       123\n",
      "           1       0.94      0.97      0.96      1022\n",
      "\n",
      "    accuracy                           0.92      1145\n",
      "   macro avg       0.81      0.73      0.76      1145\n",
      "weighted avg       0.91      0.92      0.91      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(confusion_matrix(temp_test_labels,dt_predictions))\n",
    "print(classification_report(temp_test_labels,dt_predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9283842794759826"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 51
    }
   ],
   "source": [
    "\n",
    "#Random Forest\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(temp_train_data, temp_train_label)\n",
    "\n",
    "coreml_model_rf = sklearn.convert(rfc, key_words, 'output')\n",
    "coreml_model_rf.save('coreml_rf.mlmodel')\n",
    "\n",
    "dt_predictions = rfc.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'output': 1,\n 'classProbability': {0: -6.661338147750939e-16, 1: 1.0000000000000007}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "model = coremltools.models.MLModel('coreml_rf.mlmodel')\n",
    "# model.predict({'input': temp_test_data})\n",
    "pred_out_put = model.predict({'account':42.11758, 'member':19.31017, 'access':17.05149, 'email':16.6749, 'address':15.3276,\n",
    "             'update':15.3276, 'price':12.55556, 'market':10.23963, 'online':9.770984, 'information':9.474589,\n",
    "             'work':8.331161, 'credit':5.883471, 'response':4.504742, 'offer':3.3573, 'transaction':2.809165,\n",
    "             'agreement':1.863823, 'registration':1.791679, 'person':1.522086, 'system':1.276965,\n",
    "             'process':1.076627, 'service':0.895862, 'request':0.616316, 'message':0.32805})\n",
    "print(pred_out_put[\"output\"])\n",
    "pred_out_put\n",
    "# accuracy_score(temp_test_labels,dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Random Forest\n",
      "[[  59   64]\n",
      " [  18 1004]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.48      0.59       123\n",
      "           1       0.94      0.98      0.96      1022\n",
      "\n",
      "    accuracy                           0.93      1145\n",
      "   macro avg       0.85      0.73      0.78      1145\n",
      "weighted avg       0.92      0.93      0.92      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "print(confusion_matrix(temp_test_labels,dt_predictions))\n",
    "print(classification_report(temp_test_labels,dt_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/lidayuan/opt/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.9336244541484716"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 54
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(temp_train_data, temp_train_label)\n",
    "\n",
    "log_predictions = log_model.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,log_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Logistic Regression\n",
      "[[  66   57]\n",
      " [  19 1003]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.54      0.63       123\n",
      "           1       0.95      0.98      0.96      1022\n",
      "\n",
      "    accuracy                           0.93      1145\n",
      "   macro avg       0.86      0.76      0.80      1145\n",
      "weighted avg       0.93      0.93      0.93      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Logistic Regression\")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,log_predictions))\n",
    "\n",
    "print(classification_report(temp_test_labels,log_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9336244541484716"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 56
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "###create decision tree classifier object\n",
    "DT = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=4)\n",
    "##fit decision tree model with training data\n",
    "DT.fit(temp_train_data, temp_train_label)\n",
    "##test data prediction\n",
    "DT_expost_preds = DT.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,DT_expost_preds)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "gini decision tree classifier \n",
      "[[  63   60]\n",
      " [  16 1006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.51      0.62       123\n",
      "           1       0.94      0.98      0.96      1022\n",
      "\n",
      "    accuracy                           0.93      1145\n",
      "   macro avg       0.87      0.75      0.79      1145\n",
      "weighted avg       0.93      0.93      0.93      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "print(\"gini decision tree classifier \")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,DT_expost_preds))\n",
    "print(classification_report(temp_test_labels,DT_expost_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9327510917030568"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 58
    }
   ],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "dtree.fit(temp_train_data, temp_train_label)\n",
    "\n",
    "coreml_model = sklearn.convert(dtree, key_words, 'output')\n",
    "coreml_model.save('coreml_dtree.mlmodel')\n",
    "\n",
    "pred = dtree.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'output': 1, 'classProbability': {0: 0.0, 1: 1.0}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 59
    }
   ],
   "source": [
    "model = coremltools.models.MLModel('coreml_dtree.mlmodel')\n",
    "# model.predict({'input': temp_test_data})\n",
    "pred_out_put = model.predict({'account':42.11758, 'member':19.31017, 'access':17.05149, 'email':16.6749, 'address':15.3276,\n",
    "             'update':15.3276, 'price':12.55556, 'market':10.23963, 'online':9.770984, 'information':9.474589,\n",
    "             'work':8.331161, 'credit':5.883471, 'response':4.504742, 'offer':3.3573, 'transaction':2.809165,\n",
    "             'agreement':1.863823, 'registration':1.791679, 'person':1.522086, 'system':1.276965,\n",
    "             'process':1.076627, 'service':0.895862, 'request':0.616316, 'message':0.32805})\n",
    "print(pred_out_put[\"output\"])\n",
    "pred_out_put\n",
    "# accuracy_score(temp_test_labels,dt_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "entropy decision tree classifier \n",
      "[[  62   61]\n",
      " [  16 1006]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.62       123\n",
      "           1       0.94      0.98      0.96      1022\n",
      "\n",
      "    accuracy                           0.93      1145\n",
      "   macro avg       0.87      0.74      0.79      1145\n",
      "weighted avg       0.93      0.93      0.93      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"entropy decision tree classifier \")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,pred))\n",
    "print(classification_report(temp_test_labels,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/lidayuan/opt/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.9222707423580786"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 61
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# only linearSVC can be converted \n",
    "from sklearn.svm import LinearSVC as SVC\n",
    "# svc=SVC(kernel='sigmoid')\n",
    "svc=SVC()\n",
    "inputs = np.asarray(temp_train_data, dtype=float)\n",
    "outputs = np.asarray(temp_train_label, dtype=int)\n",
    "model_5=svc.fit(inputs, outputs)\n",
    "\n",
    "coreml_model = sklearn.convert(model_5, key_words, 'output')\n",
    "coreml_model.save('coreml_svm.mlmodel')\n",
    "\n",
    "pred = model_5.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'output': 1,\n 'classProbability': {0: 0.07585059149112783, 1: 0.9241494085088722}}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 62
    }
   ],
   "source": [
    "model = coremltools.models.MLModel('coreml_svm.mlmodel')\n",
    "# model.predict({'input': temp_test_data})\n",
    "pred_out_put = model.predict({'account':42.11758, 'member':19.31017, 'access':17.05149, 'email':16.6749, 'address':15.3276,\n",
    "             'update':15.3276, 'price':12.55556, 'market':10.23963, 'online':9.770984, 'information':9.474589,\n",
    "             'work':8.331161, 'credit':5.883471, 'response':4.504742, 'offer':3.3573, 'transaction':2.809165,\n",
    "             'agreement':1.863823, 'registration':1.791679, 'person':1.522086, 'system':1.276965,\n",
    "             'process':1.076627, 'service':0.895862, 'request':0.616316, 'message':0.32805})\n",
    "print(pred_out_put[\"output\"])\n",
    "pred_out_put"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "svm \n",
      "[[ 69  54]\n",
      " [ 35 987]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       123\n",
      "           1       0.95      0.97      0.96      1022\n",
      "\n",
      "    accuracy                           0.92      1145\n",
      "   macro avg       0.81      0.76      0.78      1145\n",
      "weighted avg       0.92      0.92      0.92      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"svm \")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,pred))\n",
    "print(classification_report(temp_test_labels,pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9283842794759826"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 64
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adc=AdaBoostClassifier(n_estimators=5,learning_rate=1)\n",
    "model_6=adc.fit(temp_train_data, temp_train_label)\n",
    "\n",
    "pred = model_6.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "AdaBoostClassifier \n",
      "[[  63   60]\n",
      " [  22 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.51      0.61       123\n",
      "           1       0.94      0.98      0.96      1022\n",
      "\n",
      "    accuracy                           0.93      1145\n",
      "   macro avg       0.84      0.75      0.78      1145\n",
      "weighted avg       0.92      0.93      0.92      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"AdaBoostClassifier \")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,pred))\n",
    "print(classification_report(temp_test_labels,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9327510917030568"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 66
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb=XGBClassifier()\n",
    "# model_7=xgb.fit(temp_train_data, temp_train_label)\n",
    "# pred = model_7.predict(temp_test_data)\n",
    "model_7=xgb.fit(np.asarray(temp_train_data, dtype=float), np.asarray(temp_train_label, dtype=int))\n",
    "pred = model_7.predict(np.asarray(temp_test_data))\n",
    "\n",
    "\n",
    "accuracy_score(temp_test_labels,pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "xgboost \n",
      "[[  68   55]\n",
      " [  22 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.55      0.64       123\n",
      "           1       0.95      0.98      0.96      1022\n",
      "\n",
      "    accuracy                           0.93      1145\n",
      "   macro avg       0.85      0.77      0.80      1145\n",
      "weighted avg       0.93      0.93      0.93      1145\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"xgboost \")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,pred))\n",
    "print(classification_report(temp_test_labels,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9336244541484716"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 72
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb=GradientBoostingClassifier()\n",
    "model_gb=gb.fit(temp_train_data, temp_train_label)\n",
    "\n",
    "# coreml_model = sklearn.convert(model_gb, key_words, 'output')\n",
    "# coreml_model.save('coreml_gb.mlmodel')\n",
    "\n",
    "pred = model_gb.predict(temp_test_data)\n",
    "accuracy_score(temp_test_labels,pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"AdaBoostClassifier \")\n",
    "\n",
    "print(confusion_matrix(temp_test_labels,pred))\n",
    "print(classification_report(temp_test_labels,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}